---

# This role, is responsible for running jobs.
#
# First, it determines if it needs to enqueue (i.e., start) a new job.
# The result of this is a variable: `exp_jobs_to_enqueue` that contains
# a list with all required information to enqueue a new job in the task spooler.
# (if if is a single instance experiment -> enqueue all pending jobs
# else + there is no job currently running -> enqueue the first pending job )
#
# Second, for all jobs to enqueue it prepares the environment on the host
# (e.g., creates directories + writes config.json file)
#
# After giving the jobs to the task spooler, we wait for the highest prio job to finish.
# (we do this in a loop until loop with `job_n_tries` retries and a delay of `job_check_wait_time` in between)
#
# When the job finishes, then we download the results and update the state.
# -> When the role ends, either the number of tries is exceeded and the playbook ends, or then ONE job is finished
#     and we downloaded the results. Since this role is called in a loop for each job, as long as the number of tries never exceeds,
#     we finish all jobs of an experiment.

- assert:
    that:
    - inventory_hostname in groups['is_controller_yes']
    - is_controller # this role is running on a controller host (one per experiment is controller)
    - exp_name is defined
    - suite_id is defined
    - remote.dir is defined
    - remote.results_dir is defined
    - job_check_wait_time is defined
    - exp_runs_ext is defined
    - exp_host_lst is defined # list of hosts involved in experiment
        #[{"host_type": x, "exp_host_type_idx": x, "exp_host_type_n": x, "is_controller": x, "public_dns_name": x, "private_dns_name": x}]


  # via https://stackoverflow.com/questions/64208241/how-to-get-variables-from-all-hosts-in-ansible
- name: Check if any host failed
  set_fact:
    failed_tasks: "{{ hostvars | dict2items | selectattr('value.failed_task', 'defined') | map(attribute='value.failed_task') }}"

- name: End execution if any host failed
  fail:
    msg: "Setup failed on at least one host: {{ failed_tasks }}"
  when:
    - (failed_tasks | length>0)
    - hostvars['localhost']['any_errors_fatal_experiments']

#- debug:
#    var: exp_host_lst
#
#- debug:
#    msg=' ip= {{ exp_host_lst | json_query("[?host_type=='server'].private_dns_name") | first }} '

- name: mark that from here up to the status check, no error is expected
  set_fact:
  # in the calling playbook we have a rescue block that should handle the error when the number of retries is exceeded.
    # -> however, all other errors should be thrown and not rescued -> this info variable helps to detect where the error occurred in the role
    is_expected_error: False


###################################################################
#  Start: Schedule new Jobs (enqueue task in task spooler)        #
###################################################################

- name: Schedule new Jobs
  # only schedule new jobs when there are no jobs queued or running atm
  when: exp_job_ids_pending | length > 0 and exp_job_ids_queued | length == 0 and exp_job_ids_running | length == 0
  block:

  - set_fact:
      is_single_instance_exp: "{{ exp_host_lst | length == 1}}"

  - name: Enqueue all jobs from pending because it is a single instance experiment (no synchronization required)
    set_fact:
      exp_job_ids_to_enqueue: "{{ exp_job_ids_pending }}"
    when: is_single_instance_exp

  - name: Enqueue only one job from pending because it is a multi instance experiment (synchronization required)
    set_fact:
        exp_job_ids_to_enqueue: "{{ [exp_job_ids_pending[0]] }}"
    when: not is_single_instance_exp


  - assert:
      that:
      - exp_job_ids_queued | length == 0

  - name: build job schedule list (for each host of experiment, information about job and what is required to run)
    set_fact:
      exp_jobs_to_enqueue: "{{ exp_job_ids_to_enqueue | to_job_schedule_lst(exp_host_lst, exp_runs_ext, remote.results_dir, remote.dir) }}"
    no_log: true


    ###################################################################
    #  Prepare Experiment Environment (directories, files, ...)       #
    ###################################################################


  - name: Setup job working dirs (config.json + create results/scratch dirs)
    setup_job_dirs:
      jobs: "{{ jobs_grouped | last }}"
    delegate_to: "{{ jobs_grouped | first }}" # first entry in group
    loop: "{{ exp_jobs_to_enqueue | groupby('host_info.ansible_host_id') }}"
    loop_control:
      loop_var: jobs_grouped
    no_log: true


    ###################################################################
    #  Enqueue all Jobs                                               #
    ###################################################################

  # include_role
  - name: Enqueue jobs on scheduler
    include_role:
      name: suite-scheduler-enqueue
      tasks_from: "{{ _job_scheduler }}"
      # In the future, we can define this as an additional config parameter.

  - name: Update experiment state
    set_fact:
      exp_job_ids_queued: "{{ exp_job_ids_to_enqueue }}"
      exp_job_ids_pending: "{{  exp_job_ids_pending | difference(exp_job_ids_to_enqueue) }}"
      exp_job_ids_to_enqueue: []



###################################################################
#  End: Schedule new Jobs (enqueue task in task spooler)        #
###################################################################




###################################################################
#  Wait and the Get Status of All Job                             #
###################################################################

- name: Wait until new jobs complete
  when: exp_job_ids_queued | length > 0
  block:

  - name: Save the updated state of the experiment run (save job ids)
    include_role:
      name: experiment-state
    vars:
      expstate: save


  - name: mark that in the next task, there could be an expected error (number of retires exceeded)
    set_fact:
      is_expected_error: True


  - name: Get status of job
    include_role:
      name: suite-scheduler-status
      tasks_from: "{{ _job_scheduler }}"
      # In the future, we can define this as an additional config parameter.


  - name: mark that from here on, any error is unexpected
    set_fact:
      is_expected_error: False


  - assert:
      that:
      - exp_job_ids_completing is defined # <- these are the job ids that we now need to fetch the results from


###################################################################
#  Download Results for newly finished job                        #
###################################################################



- name: Collect Results
  delegate_to: localhost
  when: exp_job_ids_queued | length > 0
  collect_results:
    job_ids_ready_to_collect_results: "{{ exp_job_ids_completing }}"
    exp_host_lst: "{{ exp_host_lst }}"
    local_result_dir: "{{ local.results_dir}}"
    remote_result_dir: "{{ hostvars[my_host.ansible_host_id].remote.results_dir }}"
  loop: "{{ exp_host_lst }}"
  loop_control:
    loop_var: my_host


- name: Run ETL Pipeline
  when: exp_job_ids_queued | length > 0
  block:
    - name: Run ETL pipeline over results files (start)
      delegate_to: localhost
      ansible.builtin.shell:
        cmd: python ../doespy/doespy/etl/etl.py --suite {{ suite }} --id {{ suite_id }}
  rescue:
    - name: Inform about etl errors
      fail:
        msg: "Error occured in the etl pipeline -> cannot produce results but we continue with running the experiment \n(error details: {{ etl_error_file }})"
      ignore_errors: True

    - name: Creating Error File
      delegate_to: localhost
      copy:
        dest: "{{ etl_error_file }}"
        content: "{{ ansible_failed_result | to_nice_yaml }}"
  vars:
    etl_error_file: "{{ local.results_dir}}/{{ suite }}_{{ suite_id }}/ETL_ERROR.log"


- set_fact:
    cur_exp_job_ids_queued: "{{ exp_job_ids_queued }}"

- name: Post cleanup / update
  when: cur_exp_job_ids_queued | length > 0
  block:

  ###################################################################
  #  Cleanup task spooler queue                                     #
  ###################################################################

  - name: Remove finished job with downloaded results from queue
    include_role:
      name: suite-scheduler-remove
      tasks_from: "{{ _job_scheduler }}"
      # In the future, we can define this as an additional config parameter.

  ###################################################################
  #  Update experiment state                                        #
  ###################################################################

  - name: update vars 1
    set_fact:
      exp_job_ids_running: []
      exp_job_ids_finished: "{{ exp_job_ids_finished | list + exp_job_ids_completing | list  }}"
      exp_job_ids_queued: "{{ exp_job_ids_queued | difference(exp_job_ids_completing) | list }}" # remove all exp_job_ids_completing from exp_job_ids_queued
      exp_job_ids_completing: []

  - name: update vars 2
    set_fact:
      exp_job_ids_unfinished: "{{ exp_job_ids_pending | list + exp_job_ids_queued | list + exp_job_ids_running | list}}"

  - name: Save the updated state of the experiment run (save job ids)
    include_role:
      name: experiment-state
    vars:
      expstate: save


  ###################################################################
  #  Compute suite progress info and output                         #
  ###################################################################

  - name: compute overview of progress in different experiments in suite
    set_fact:
      suite_progress_info: "{{ suite_progress_info | default({}) | combine({my_exp_name: {'require_suite_to_finish': my_require_suite ,'n_finished': my_n_finished | int, 'n_unfinished': my_n_unfinished | int, 'progress':  (my_n_finished | int / (my_n_finished | int + my_n_unfinished | int) * 100) | round(2) | string + ' %' }})}}"
    vars:
      my_exp_name: "{{ hostvars[my_controller_host].exp_name }}"
      my_n_unfinished: "{{ hostvars[my_controller_host].exp_job_ids_unfinished | length }}"
      my_require_suite: "{{ hostvars[my_controller_host].exp_job_ids_pending | length > 0 }}"
      my_n_finished: "{{ hostvars[my_controller_host].exp_job_ids_finished | length }}"
    loop: "{{ groups['is_controller_yes'] }}"
    loop_control:
      loop_var: my_controller_host

  - name: output progress information of experiments
    debug:
      msg: "{{ suite_progress_info[item] }}"
    loop: "{{ suite_progress_info.keys() | sort }}"
    tags: [print_action]