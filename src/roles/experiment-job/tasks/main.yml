---

# This role, is responsible for running jobs.
#
# First, it determines if it needs to enqueue (i.e., start) a new job.
# The result of this is a variable: `exp_jobs_to_enqueue` that contains
# a list with all required information to enqueue a new job in the task spooler.
# (if if is a single instance experiment -> enqueue all pending jobs
# else + there is no job currently running -> enqueue the first pending job )
#
# Second, for all jobs to enqueue it prepares the environment on the host
# (e.g., creates directories + writes config.json file)
#
# After giving the jobs to the task spooler, we wait for the highest prio job to finish.
# (we do this in a loop until loop with `job_n_tries` retries and a delay of `job_check_wait_time` in between)
#
# When the job finishes, then we download the results and update the state.
# -> When the role ends, either the number of tries is exceeded and the playbook ends, or then ONE job is finished
#     and we downloaded the results. Since this role is called in a loop for each job, as long as the number of tries never exceeds,
#     we finish all jobs of an experiment.

- assert:
    that:
    - inventory_hostname in groups['is_controller_yes']
    - is_controller # this role is running on a controller host (one per experiment is controller)
    - exp_name is defined
    - suite_id is defined
    - job_check_wait_time is defined
    - exp_runs_ext is defined
    - exp_host_lst is defined # list of hosts involved in experiment
        #[{"host_type": x, "exp_host_type_idx": x, "exp_host_type_n": x, "is_controller": x, "public_dns_name": x, "private_dns_name": x}]


  # via https://stackoverflow.com/questions/64208241/how-to-get-variables-from-all-hosts-in-ansible
- name: Check if any host failed
  set_fact:
    failed_tasks: "{{ hostvars | dict2items | selectattr('value.failed_task', 'defined') | map(attribute='value.failed_task') }}"

- name: End execution if any host failed
  fail:
    msg: "Setup failed on at least one host: {{ failed_tasks }}"
  when:
    - (failed_tasks | length>0)
    - hostvars['localhost']['any_errors_fatal_experiments']

#- debug:
#    var: exp_host_lst
#
#- debug:
#    msg=' ip= {{ exp_host_lst | json_query("[?host_type=='server'].private_dns_name") | first }} '

- name: mark that from here up to the status check, no error is expected
  set_fact:
  # in the calling playbook we have a rescue block that should handle the error when the number of retries is exceeded.
    # -> however, all other errors should be thrown and not rescued -> this info variable helps to detect where the error occurred in the role
    is_expected_error: False


###################################################################
#  Start: Schedule new Jobs (enqueue task in task spooler)        #
###################################################################

- name: Schedule new Jobs
  # only schedule new jobs when there are no jobs queued or running atm
  when: exp_job_ids_pending | length > 0 and exp_job_ids_queued | length == 0 and exp_job_ids_running | length == 0
  block:

  - set_fact:
      is_single_instance_exp: "{{ exp_host_lst | length == 1}}"

  - name: Enqueue all jobs from pending because it is a single instance experiment (no synchronization required)
    set_fact:
      exp_job_ids_to_enqueue: "{{ exp_job_ids_pending }}"
    when: is_single_instance_exp

  - name: Enqueue only one job from pending because it is a multi instance experiment (synchronization required)
    set_fact:
        exp_job_ids_to_enqueue: "{{ [exp_job_ids_pending[0]] }}"
    when: not is_single_instance_exp


  - assert:
      that:
      - exp_job_ids_queued | length == 0

  - name: build job schedule list (for each host of experiment, information about job and what is required to run)
    set_fact:
      exp_jobs_to_enqueue: "{{ exp_job_ids_to_enqueue | to_job_schedule_lst(exp_host_lst, exp_runs_ext, remote.results_dir) }}"


    ###################################################################
    #  Prepare Experiment Environment (directories, files, ...)       #
    ###################################################################

  - name: Create results and scratch directories (per-host)
    ansible.builtin.shell: >
      mkdir -m755 -p
      {{ jobs_grouped | last | map(attribute='exp_working_dir') | map('regex_replace', '^(.*)$', '\1/scratch') | join(' ') }}
      {{ jobs_grouped | last | map(attribute='exp_working_dir') | map('regex_replace', '^(.*)$', '\1/results') | join(' ') }}
    delegate_to: "{{ jobs_grouped | first }}" # first entry in group
    loop: "{{ exp_jobs_to_enqueue | groupby('host_info.public_dns_name') }}"
    loop_control:
      loop_var: jobs_grouped

#  - name: Create results and scratch directories (per-host)
#    ansible.builtin.command:
#      cmd: mkdir -m755 -p {{ '{' }}{{ jobs_grouped | last | map(attribute='exp_working_dir') | map('regex_replace', '^(.*)$', '\1/scratch') | map('quote') | join(',') }}{{ '}' }}
##      mkdir -m755 -p {{ '{' }}{{ jobs_grouped | last | map(attribute='exp_working_dir') | map('regex_replace', '^(.*)$', '\1/results') | join(',') }}{{ '}' }}
#    delegate_to: "{{ jobs_grouped | first }}" # first entry in group
#    loop: "{{ exp_jobs_to_enqueue | groupby('host_info.public_dns_name') }}"
#    loop_control:
#        loop_var: jobs_grouped

  - name: Create run config file in working directory
    template:
        src: config.json.j2
        dest: "{{ job.exp_working_dir }}/config.json"
        mode: 0755
    delegate_to: "{{ job.host_info.public_dns_name }}"
    loop: "{{ exp_jobs_to_enqueue }}"
    loop_control:
        loop_var: job

    ###################################################################
    #  Enqueue all Jobs                                               #
    ###################################################################

  # include_role
  - name: Enqueue jobs on scheduler
    include_role:
      name: suite-scheduler-enqueue
      tasks_from: "{{ job_scheduler }}"
      # In the future, we can define this as an additional config parameter.

  - name: Update experiment state
    set_fact:
      exp_job_ids_queued: "{{ exp_job_ids_to_enqueue }}"
      exp_job_ids_pending: "{{  exp_job_ids_pending | difference(exp_job_ids_to_enqueue) }}"
      exp_job_ids_to_enqueue: []

###################################################################
#  End: Schedule new Jobs (enqueue task in task spooler)        #
###################################################################




###################################################################
#  Wait and the Get Status of All Job                             #
###################################################################


- name: Set the job id to wait until finished + update state
  set_fact:
    job_id_to_wait_for: "{{ cur_job_id }}"
    exp_job_ids_queued: "{{ exp_job_ids_queued | difference([cur_job_id]) }}"
    exp_job_ids_running: "{{ [cur_job_id] }}"
  vars:
    # if there is still a running_job_id then take this one, else take the first of the queued jobs
    cur_job_id:  "{{ (exp_job_ids_running | list + exp_job_ids_queued | list) | first }}"


- name: Save the updated state of the experiment run (save job ids)
  include_role:
    name: experiment-state
  vars:
    expstate: save


- name: mark that in the next task, there could be an expected error (number of retires exceeded)
  set_fact:
    is_expected_error: True


- name: Get status of job
  include_role:
    name: suite-scheduler-status
    tasks_from: "{{ job_scheduler }}"
    # In the future, we can define this as an additional config parameter.


- name: mark that from here on, any error is unexpected
  set_fact:
    is_expected_error: False

###################################################################
#  Download Results for newly finished job                        #
###################################################################

- name: Download Results
  block:

  - debug:
      msg:
      - "remote_results_dir={{ remote_results_dir }}"
      - "local_results_dir_base={{ local_results_dir_base }}"
      - "remote_config_file= {{ remote_config_file }}"

  - name: Create local folder (for results)
    delegate_to: localhost
    file:
      path: "{{ local_results_dir_base }}/{{ my_host.host_type }}/host_{{ my_host.exp_host_type_idx }}"
      state: directory
      mode: 0755
    loop: "{{ exp_host_lst }}"
    loop_control:
      loop_var: my_host

  - name: Fetch Results (if experiment done)
    delegate_to: localhost
    local_action: command rsync -az "{{ my_host.public_dns_name }}:{{ remote_results_dir }}/*" "{{ local_results_dir_base }}/{{ my_host.host_type }}/host_{{ my_host.exp_host_type_idx }}"
    loop: "{{ exp_host_lst }}"
    loop_control:
      loop_var: my_host

  - name: Save the config of the job
    delegate_to: localhost
    local_action: "command rsync -az '{{ my_host.public_dns_name }}:{{ remote_config_file }}' '{{ local_results_dir_base }}'"
    loop: "{{ exp_host_lst[:1] }}"
    loop_control:
      loop_var: my_host

  - name: Run ETL Pipeline
    block:

      - name: Run ETL pipeline over results files (start)
        delegate_to: localhost
        ansible.builtin.shell:
          cmd: python ../doespy/doespy/etl/etl.py --suite {{ suite }} --id {{ suite_id }}
        when: ((current_exec_etl | int - previous_exec_etl | default(0) | int) > (etl_minimum_delay_sec|int))  or exp_job_ids_unfinished | list | length == 1

      - name: update prev timestamp
        set_fact:
          is_exec: True
          previous_exec_etl: "{{ current_exec_etl }}"
        when: ((current_exec_etl | int - previous_exec_etl | default(0) | int) > (etl_minimum_delay_sec|int))  or exp_job_ids_unfinished | list | length == 1

    rescue:
      - name: Inform about etl errors
        fail:
          msg: "Error occured in the etl pipeline -> cannot produce results but we continue with running the experiment \n(error details: {{ etl_error_file }})"
        ignore_errors: True

      - name: Creating Error File
        delegate_to: localhost
        copy:
          dest: "{{ etl_error_file }}"
          content: "{{ ansible_failed_result | to_nice_yaml }}"
    vars:
    - etl_error_file: "{{ local.results_dir}}/{{ suite }}_{{ suite_id }}/ETL_ERROR.log"
    - current_exec_etl: "{{ lookup('pipe', 'date +%s') }}"


  vars:
  - remote_results_dir: "{{ job_id_to_wait_for | jobid2workingdir(remote.results_dir) + '/results' }}"
  - local_results_dir_base: "{{ job_id_to_wait_for | jobid2workingdir(local.results_dir) }}"
  - remote_config_file: "{{ job_id_to_wait_for | jobid2workingdir(remote.results_dir) + '/config.json' }}"



###################################################################
#  Cleanup task spooler queue                                     #
###################################################################

- name: Remove finished job with downloaded results from queue
  include_role:
    name: suite-scheduler-remove
    tasks_from: "{{ job_scheduler }}"
    # In the future, we can define this as an additional config parameter.


###################################################################
#  Update experiment state                                        #
###################################################################

- name: update vars 1
  set_fact:
    exp_job_ids_running: []
    exp_job_ids_finished: "{{ exp_job_ids_finished | list + [job_id_to_wait_for] }}"

- name: update vars 2
  set_fact:
    exp_job_ids_unfinished: "{{ exp_job_ids_pending | list + exp_job_ids_queued | list + exp_job_ids_running | list}}"

- name: Save the updated state of the experiment run (save job ids)
  include_role:
    name: experiment-state
  vars:
    expstate: save


###################################################################
#  Compute suite progress info and output                         #
###################################################################

- name: compute overview of progress in different experiments in suite
  set_fact:
    suite_progress_info: "{{ suite_progress_info | default({}) | combine({my_exp_name: {'require_suite_to_finish': my_require_suite ,'n_finished': my_n_finished | int, 'n_unfinished': my_n_unfinished | int, 'progress':  (my_n_finished | int / (my_n_finished | int + my_n_unfinished | int) * 100) | round(2) | string + ' %' }})}}"
  vars:
    my_exp_name: "{{ hostvars[my_controller_host].exp_name }}"
    my_n_unfinished: "{{ hostvars[my_controller_host].exp_job_ids_unfinished | length }}"
    my_require_suite: "{{ hostvars[my_controller_host].exp_job_ids_pending | length > 0 }}"
    my_n_finished: "{{ hostvars[my_controller_host].exp_job_ids_finished | length }}"
  loop: "{{ groups['is_controller_yes'] }}"
  loop_control:
    loop_var: my_controller_host

- name: output progress information of experiments
  debug:
    msg: "{{ suite_progress_info[item] }}"
  loop: "{{ suite_progress_info.keys() | sort }}"
  tags: [print_action]