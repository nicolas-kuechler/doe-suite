---

- assert:
    that:
      - exp_jobs_to_enqueue is defined
      - exp_name is defined

- name: schedule the job on leonhard using bsub
  vars:
    experiment_name: "{{ exp_id }}_{{ run_id }}_{{ exp_idx }}"
    output_file: "lsf.ans.%J.{{ exp_id }}_{{ run_id }}_{{ exp_idx }}.out"
  register: bsub_output
  shell: |
    source /etc/profile
    source ~/.bash_profile
    . /cluster/apps/local/env2lmod.sh
    module load gcc/6.3.0 python/3.7.4 hdf5/1.10.1 cuda/10.1.243 cudnn/7.6.4 nccl/2.4.8-1
    pip install --user pipenv
    python -m pipenv lock -r > requirements.txt
    pip install --user -r requirements.txt
    bsub -W {{ exp_config.job.minutes }} -n {{ exp_config.job.cpu_cores }} -J {{ experiment_name }} -oo {{ output_file }} -R "rusage[mem={{ exp_config.job.cpu_mem_per_core}},ngpus_excl_p={{ exp_config.job.use_gpu }}]" -R "select[gpu_mtotal0>={{ exp_config.job.gpu_memory_min }}]" -N "python -m src.main -c {{ config_path }}"
  args:
    chdir: "{{ analysis_framework_dir }}"
    executable: /bin/bash

#- name: Clear task spooler queue on each host (+ stop all running jobs)
#  tsp:
#    clear_tasks: True
#  delegate_to: "{{ host }}"
#  loop: "{{ groups[exp_name] }}"
#  loop_control:
#    loop_var: host
#
#- name: Enqueue all jobs on the task spooler
#  tsp:
#    cmd: "{{ job.exp_run_cmd }}"
#    cmd_label: "{{ job.job_info | to_json | string }}"
#    cmd_working_dir: "{{ job.exp_working_dir }}"
#    cmd_stdout_file: results/stdout.log # relative path compared to working dir
#    cmd_stderr_file: results/stderr.log
#  delegate_to: "{{ job.host_info.public_dns_name }}"
#  loop: "{{ exp_jobs_to_enqueue }}"
#  loop_control:
#    loop_var: job